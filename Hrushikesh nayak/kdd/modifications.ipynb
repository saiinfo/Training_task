{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, accuracy_score\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_iris\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "import psutil\n",
    "import time\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('KDDTrain+.txt')\n",
    "columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted'\n",
    ",'num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate'\n",
    ",'srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
    "'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','attack','level'])\n",
    "\n",
    "data.columns = columns\n",
    "data = data.drop('level', axis=1)\n",
    "data.tail()\n",
    "\n",
    "# changing attack labels to their respective attack class\n",
    "def change_label(df):\n",
    "  df.attack.replace(['apache2','back','land','neptune','mailbomb','pod','processtable','smurf','teardrop','udpstorm','worm'],'Dos',inplace=True)\n",
    "  df.attack.replace(['ftp_write','guess_passwd','httptunnel','imap','multihop','named','phf','sendmail','snmpgetattack','snmpguess','spy','warezclient','warezmaster','xlock','xsnoop'],'R2L',inplace=True)      \n",
    "  df.attack.replace(['ipsweep','mscan','nmap','portsweep','saint','satan'],'Probe',inplace=True)\n",
    "  df.attack.replace(['buffer_overflow','loadmodule','perl','ps','rootkit','sqlattack','xterm'],'U2R',inplace=True)\n",
    "\n",
    "change_label(data)\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['protocol_type']=le.fit_transform(data['protocol_type'])\n",
    "data['service']=le.fit_transform(data['service'])\n",
    "data['flag']=le.fit_transform(data['flag'])\n",
    "data['attack']=le.fit_transform(data['attack'])\n",
    "\n",
    "def cross_val(x_train, y_train, model):\n",
    "    accuracies = cross_val_score(estimator = model, X = x_train, y = y_train, cv=5)\n",
    "    return accuracies.mean()\n",
    "\n",
    "def fit_and_evaluate(model, x_train , x_test , y_train , y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    model_pred = model.predict(x_test)\n",
    "    model_cross = cross_val(x_train, y_train, model)\n",
    "    \n",
    "    return model_cross\n",
    "\n",
    "def run_experiment(model, x_train , x_test , y_train , y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"R^2 : \", r2_score(y_test, y_pred))\n",
    "    print(\"MAE :\", mean_absolute_error(y_test,y_pred))\n",
    "    print(\"RMSE:\",np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    report=classification_report(y_test,y_pred)\n",
    "    print(report)\n",
    "\n",
    "x = data.drop(['attack'], axis=1).values\n",
    "y = data['attack'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RandomForestClassifier Accuracy: 0.9984520738241714\n",
      "memory usage: 94.968884 MB\n",
      "Elapsed Time: 5.2776 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tracemalloc\n",
    "import time\n",
    "data = pd.read_csv('KDDTrain+.txt')\n",
    "columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted'\n",
    ",'num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate'\n",
    ",'srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
    "'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','attack','level'])\n",
    "data.columns = columns\n",
    "data = data.drop('level', axis=1)\n",
    "data.tail()\n",
    "le = LabelEncoder()\n",
    "data['protocol_type'] = le.fit_transform(data['protocol_type'])\n",
    "data['service'] = le.fit_transform(data['service'])\n",
    "data['flag'] = le.fit_transform(data['flag'])\n",
    "data['attack'] = le.fit_transform(data['attack'])\n",
    "x = data.drop(['attack'], axis=1)\n",
    "y = data['attack']\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\" RandomForestClassifier Accuracy:\", accuracy)\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"memory usage: {peak / 10**6} MB\")\n",
    "end_time =time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed Time: {elapsed_time:.4f} seconds\")\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Accuracy: 0.8598380609652837\n",
      "memory usage: 88.758898 MB\n",
      "Elapsed Time: 0.9333 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tracemalloc\n",
    "import time\n",
    "data = pd.read_csv('KDDTrain+.txt')\n",
    "columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted'\n",
    ",'num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate'\n",
    ",'srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
    "'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','attack','level'])\n",
    "data.columns = columns\n",
    "data = data.drop('level', axis=1)\n",
    "data.tail()\n",
    "le = LabelEncoder()\n",
    "data['protocol_type'] = le.fit_transform(data['protocol_type'])\n",
    "data['service'] = le.fit_transform(data['service'])\n",
    "data['flag'] = le.fit_transform(data['flag'])\n",
    "data['attack'] = le.fit_transform(data['attack'])\n",
    "x = data.drop(['attack'], axis=1)\n",
    "y = data['attack']\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=50)\n",
    "clf = RandomForestClassifier(n_estimators=50, criterion='entropy', max_depth=None, min_samples_split=0.4, min_samples_leaf=1,\n",
    "                              max_features='log2', oob_score=False, verbose=0, warm_start=False)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"RandomForestClassifier Accuracy:\", accuracy)\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"memory usage: {peak / 10**6} MB\")\n",
    "end_time =time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed Time: {elapsed_time:.4f} seconds\")\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.11974618\n",
      "Validation score: 0.989453\n",
      "Iteration 2, loss = 0.03499875\n",
      "Validation score: 0.992062\n",
      "Iteration 3, loss = 0.03011508\n",
      "Validation score: 0.990587\n",
      "Iteration 4, loss = 0.02568939\n",
      "Validation score: 0.993196\n",
      "Iteration 5, loss = 0.02359463\n",
      "Validation score: 0.994783\n",
      "Iteration 6, loss = 0.02064389\n",
      "Validation score: 0.993649\n",
      "Iteration 7, loss = 0.01980911\n",
      "Validation score: 0.993990\n",
      "Iteration 8, loss = 0.01972849\n",
      "Validation score: 0.993763\n",
      "Iteration 9, loss = 0.01797933\n",
      "Validation score: 0.994670\n",
      "Iteration 10, loss = 0.01698797\n",
      "Validation score: 0.994103\n",
      "MLPClassifier Accuracy:  0.9936759102455546\n",
      "Current memory usage is 0.986138MB; Peak was 76.26821MB\n",
      "Elapsed Time: 82.49 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(150, 100, 50), max_iter=10, alpha=1e-5,\n",
    "                    solver='adam', verbose=10, tol=1e-4, random_state=42,\n",
    "                    learning_rate_init=0.001, batch_size=64, early_stopping=True, validation_fraction=0.1)\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mlp.fit(x_train_scaled, y_train)\n",
    "y_pred_mlp = mlp.predict(x_test_scaled)\n",
    "\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"MLPClassifier Accuracy: \", accuracy_mlp)\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier Accuracy:  0.998756350550381\n",
      "Current memory usage is 0.402565MB; Peak was 29.692687MB\n",
      "Elapsed Time: 9.46 seconds\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_xgb = model.predict(x_test)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"XGBClassifier Accuracy: \", xgb_accuracy)\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier Accuracy:  0.8455493226079593\n",
      "Memory usage: 81.304239 MB\n",
      "Time taken: 5.09 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "abc = AdaBoostClassifier( random_state=0)\n",
    "abc.fit(x_train, y_train)\n",
    "\n",
    "y_pred_abc = abc.predict(x_test)\n",
    "\n",
    "accuracy_abc = accuracy_score(y_test, y_pred_abc)\n",
    "print(\"AdaBoostClassifier Accuracy: \", accuracy_abc)\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Memory usage: {peak / 10**6} MB\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9776936917866215\n",
      "Current memory usage is 1.25753MB; Peak was 50.841181MB\n",
      "Elapsed Time: 82.2798 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def ensemble_model(x_train, x_test, y_train, y_test):\n",
    "    start_time = time.time()\n",
    "    tracemalloc.start()\n",
    "\n",
    "    model1 = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=1)\n",
    "    model2 = MLPClassifier(random_state=1)\n",
    "    vote_model = VotingClassifier(estimators=[('xgb', model1), ('mlp', model2)], voting='hard')\n",
    "\n",
    "    vote_model.fit(x_train,y_train)\n",
    "    y_pred = vote_model.predict(x_test)\n",
    "\n",
    "    print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed Time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "ensemble_model(x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9776936917866215\n",
      "Current memory usage is 1.2536MB;\n",
      "Elapsed Time: 75.1514 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def model(x_train, x_test, y_train, y_test):\n",
    "    start_time = time.time()\n",
    "    tracemalloc.start()\n",
    "\n",
    "    model1 = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=1)\n",
    "    model2 = MLPClassifier(random_state=1)\n",
    "    vote_model = VotingClassifier(estimators=[('xgb', model1), ('mlp', model2)], voting='hard')\n",
    "\n",
    "    vote_model.fit(x_train,y_train)\n",
    "    y_pred = vote_model.predict(x_test)\n",
    "\n",
    "    print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    current , peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(f\"Current memory usage is {current / 10**6}MB;\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed Time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "model(x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9090812870448772\n",
      "Current memory usage is 30.089501MB;\n",
      "Elapsed Time: 17.1370 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def model(x_train, x_test, y_train, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    knn_params = {'n_neighbors': range(3,6), 'weights': ['uniform', 'distance']}\n",
    "    ada_params = {'n_estimators' : [50,100,150], 'learning_rate' : [0.01, 0.1, 1]}\n",
    "\n",
    "    knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=3)\n",
    "    ada_grid = GridSearchCV(AdaBoostClassifier(random_state=1), ada_params, cv=3)\n",
    "\n",
    "    model1 = knn_grid.fit(x_train_scaled, y_train)\n",
    "    model2 = ada_grid.fit(x_train_scaled, y_train)\n",
    "\n",
    "    vote_model = VotingClassifier(estimators=[('knn_best', model1.best_estimator_), ('ada_best', model2.best_estimator_)], voting='hard')\n",
    "\n",
    "\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "\n",
    "    vote_model.fit(x_train_scaled, y_train)\n",
    "    \n",
    "\n",
    "    y_pred = vote_model.predict(x_test_scaled)\n",
    "    \n",
    "\n",
    "    print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "    current = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    print(f\"Current memory usage is {current[0] / 10**6}MB;\")\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed Time: {elapsed_time:.4f} seconds\")\n",
    "    \n",
    "model(x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9224703640982218\n",
      "Current memory usage is 66.722999MB;\n",
      "Elapsed Time: 826.4001 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def model(x_train, x_test, y_train, y_test):\n",
    "    start_time = time.time()\n",
    "    tracemalloc.start()\n",
    "\n",
    "    model1 = KNeighborsClassifier()\n",
    "    model2 = SVC(random_state=1)  \n",
    "    model3 = GaussianNB()\n",
    "    vote_model = VotingClassifier(estimators=[('knn', model1), ('svm', model2), ('gnb', model3)], voting='hard')\n",
    "\n",
    "    vote_model.fit(x_train, y_train)\n",
    "    y_pred = vote_model.predict(x_test)\n",
    "\n",
    "    print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    current , peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(f\"Current memory usage is {current / 10**6}MB;\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed Time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "model(x_train, x_test, y_train, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
